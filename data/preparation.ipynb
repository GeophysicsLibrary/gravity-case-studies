{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and prepare the raw data for use in the lesson\n",
    "\n",
    "The raw gravity and topography data are generated from [spherical harmonic models](https://en.wikipedia.org/wiki/Spherical_harmonics) using the [ICGEM Calculation Service](http://icgem.gfz-potsdam.de). The data are distributed in text files and heights are defined relative to the geoid (orthometric heights). We need to convert the obeservation heights and topography to geometric heights (relative to the ellipsoid) using the geoid heights also downloaded from ICGEM. We'll also save this data in [netCDF](https://www.unidata.ucar.edu/software/netcdf/) files for easier loading with [xarray](http://xarray.pydata.org/).\n",
    "\n",
    "The model used to generate the gravity and geoid height data is EIGEN-6c4. The topography data is interpolated from the ETOPO1 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries\n",
    "\n",
    "We need the following libraries to do this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data and converting to an xarray grid\n",
    "\n",
    "The data are laidout in regular grids but ICGEM makes them available in a text format. That's not very efficient for computation or storage. Plus, for each location we have 3 different files: the raw gravity (with the measurement height), the geoid, and the ETOPO1 topography. \n",
    "\n",
    "We can use [`xarray.Dataset`](http://xarray.pydata.org/en/stable/data-structures.html#dataset)s to store all of these grids in a single variable and then export them into a single netCDF file.\n",
    "\n",
    "We'll start by writing a function that loads the data in a ICGEM `.gdf` file and stores them in an [`xarray.Dataset`](http://xarray.pydata.org/en/stable/data-structures.html#dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_icgem_gdf(fname, dtype = 'float32'):\n",
    "    \"\"\"\n",
    "    Load data from an ICGEM .gdf file into an xarray.Dataset.\n",
    "    \n",
    "    Reads metdata from the header, like the grid area, number of points, \n",
    "    height over the ellipsoid (if it's constant), etc.\n",
    "    \n",
    "    Stores the file header in the ``attrs`` attribute of the Dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        The name of the .gdf file.\n",
    "    dtype : str or numpy dtype object\n",
    "        The data type used when loading the data from the file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : xarray.Dataset\n",
    "     \n",
    "    \"\"\"    \n",
    "    with open(fname) as gdf_file:\n",
    "        # Read the header and extract metadata\n",
    "        header = []\n",
    "        shape = [None, None]\n",
    "        size = None\n",
    "        height_over_ell = None\n",
    "        fields = None\n",
    "        is_field_names = False\n",
    "        west, east, south, north = [None]*4\n",
    "        for line in gdf_file:\n",
    "            if line.strip()[:11] == 'end_of_head':\n",
    "                break\n",
    "            if not line.strip():\n",
    "                # The field names will come after a blank line\n",
    "                is_field_names = True\n",
    "                continue\n",
    "            header.append(line)\n",
    "            parts = line.strip().split()\n",
    "            if parts[0] == 'height_over_ell':\n",
    "                height_over_ell = float(parts[1])\n",
    "            elif parts[0] == 'latitude_parallels':\n",
    "                nlat = shape[0] = int(parts[1])\n",
    "            elif parts[0] == 'longitude_parallels':\n",
    "                nlon = shape[1] = int(parts[1])\n",
    "            elif parts[0] == 'number_of_gridpoints':\n",
    "                size = int(parts[1])\n",
    "            elif parts[0] == 'latlimit_south':\n",
    "                south = float(parts[1])\n",
    "            elif parts[0] == 'latlimit_north':\n",
    "                north = float(parts[1])\n",
    "            elif parts[0] == 'longlimit_west':\n",
    "                west = float(parts[1])\n",
    "            elif parts[0] == 'longlimit_east':\n",
    "                east = float(parts[1])\n",
    "            if is_field_names:\n",
    "                # Skip the first two because they are the coordinate\n",
    "                # names.\n",
    "                fields = line.strip().split()[2:]\n",
    "                is_field_names = False\n",
    "        # Read the numerical values\n",
    "        rawdata = np.loadtxt(gdf_file, ndmin=2, unpack=True, dtype=dtype)\n",
    "        \n",
    "    # Sanity checks\n",
    "    assert all(n is not None for n in shape), \"Couldn't read shape of grid.\"\n",
    "    assert size is not None, \"Couldn't read size of grid.\"\n",
    "    assert shape[0]*shape[1] == size, \\\n",
    "        \"Grid shape '{}' and size '{}' mismatch.\".format(shape, size)\n",
    "    assert fields is not None, \"Couldn't read column names.\"\n",
    "    assert len(fields) == rawdata.shape[0] - 2, \\\n",
    "        \"Number of attributes ({}) and data columns ({}) mismatch\".format(\n",
    "            len(fields), rawdata.shape[0] - 2)\n",
    "    assert all(i is not None for i in [west, east, south, north]), \\\n",
    "        \"Couldn't read the grid area.\"\n",
    "                \n",
    "    if height_over_ell is not None:\n",
    "        fields.append('height_over_ell')\n",
    "        rawdata.append(height_over_ell*np.ones(size, dtype=dtype))\n",
    "        \n",
    "    # Build the xarray container\n",
    "    dims = ['latitude', 'longitude']\n",
    "    latitude = np.linspace(south, north, nlat, dtype=dtype)\n",
    "    longitude = np.linspace(west, east, nlon, dtype=dtype)\n",
    "    # Cartopy doesn't like 0-360 longitude\n",
    "    longitude[longitude > 180] -= 360\n",
    "    coords = {'latitude': latitude, 'longitude': longitude}\n",
    "    attrs = {'file_header': ''.join(header)}\n",
    "    data_vars = {}\n",
    "    for name, value in zip(fields, rawdata[2:]):\n",
    "        # Need to invert the data matrices in latitude \"[::-1]\"\n",
    "        # because the ICGEM grid varies latitude from N to S\n",
    "        # instead of S to N.        \n",
    "        data_vars[name] = xr.DataArray(\n",
    "            value.reshape(shape)[::-1], coords=coords, dims=dims, name=name,\n",
    "            attrs=attrs)    \n",
    "        \n",
    "    return xr.Dataset(data_vars, attrs=attrs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this in the Hawai'i topography data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:         (latitude: 301, longitude: 301)\n",
       "Coordinates:\n",
       "  * latitude        (latitude) float32 13.0 13.05 13.1 13.15 13.2 13.25 13.3 ...\n",
       "  * longitude       (longitude) float32 -165.0 -164.95 -164.9 -164.85 -164.8 ...\n",
       "Data variables:\n",
       "    topography_grd  (latitude, longitude) float32 -3902.0 -2930.0 -3028.0 ...\n",
       "Attributes:\n",
       "    file_header:  generating_institute     gfz-potsdam\\n     generating_date ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_icgem_gdf('etopo1-hawaii.gdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now we need a function that loads each dataset from a location and combines them into a single `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_location_data(location):\n",
    "    \"\"\"\n",
    "    Load gravity, geoid, and topography data for a given location.\n",
    "    \n",
    "    Includes the computed ellipsoidal (geometric) heights computed \n",
    "    using the given geoid heights.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    location : str\n",
    "        Location name, as used in the data files.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data : xarray.Dataset\n",
    "        Combined dataset with all grids loaded from different files.\n",
    "    \"\"\"\n",
    "    gravity = load_icgem_gdf('eigen-6c4-{}-gravity.gdf'.format(location))\n",
    "    geoid = load_icgem_gdf('eigen-6c4-{}-geoid.gdf'.format(location))\n",
    "    topography = load_icgem_gdf('etopo1-{}.gdf'.format(location))\n",
    "    data = xr.merge([gravity, geoid, topography])\n",
    "    # Compute ellipsoidal (geometric) heights\n",
    "    data['h_over_ellipsoid'] = data.h_over_geoid + data.geoid\n",
    "    data['topography_ell'] = data.topography_grd + data.geoid\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it to make sure it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:           (latitude: 301, longitude: 301)\n",
       "Coordinates:\n",
       "  * latitude          (latitude) float32 13.0 13.05 13.1 13.15 13.2 13.25 ...\n",
       "  * longitude         (longitude) float32 -165.0 -164.95 -164.9 -164.85 ...\n",
       "Data variables:\n",
       "    gravity_earth     (latitude, longitude) float32 978337.0 978356.0 ...\n",
       "    h_over_geoid      (latitude, longitude) float32 0.0 0.0 0.0 0.0 0.0 0.0 ...\n",
       "    geoid             (latitude, longitude) float32 12.0905 12.123 12.0423 ...\n",
       "    topography_grd    (latitude, longitude) float32 -3902.0 -2930.0 -3028.0 ...\n",
       "    h_over_ellipsoid  (latitude, longitude) float32 12.0905 12.123 12.0423 ...\n",
       "    topography_ell    (latitude, longitude) float32 -3889.91 -2917.88 ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_location_data('hawaii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that `h_over_geoid` and `h_over_ellipsoid` refer to the observation height of the gravity measurements while `topography_grd` and `topography_ell` are topographic and bathimetric heights with respect to the geoid and ellipsoid (respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the data from all locations and save them to netCDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = 'hawaii'.split()\n",
    "for location in locations:\n",
    "    load_location_data(location).to_netcdf('{}-gravity.nc'.format(location), mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
